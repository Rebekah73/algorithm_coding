{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Means Clustering\n",
    "\n",
    "This mini project had two main goals. The first was to construct a basic k means clustering model using a variable number of clusters and a Euclidean distance function. The second was to use k means clustering to explore the relationship between class grade distributions and class subjects at the University of Wisconsin at Madison between 2006 and 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The datasets\n",
    "\n",
    "Here I use three datasets (which are a subset of the datasets that I used in the UW_Madison project).\n",
    "- ```/inputs/grade_distributions.csv``` contains the count of each grade assigned for each course section taught at the university during the given time period\n",
    "- ```/inputs/subject_memberships.csv``` contains the subject codes associated with each course section \n",
    "- ```/inputs/subjects.csv``` associates a subject name to each subject code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data\n",
    "\n",
    "grades = pd.read_csv('../UW_Madison/inputs/grade_distributions.csv')\n",
    "subject_mems = pd.read_csv('../UW_Madison/inputs/subject_memberships.csv')\n",
    "subject_names = pd.read_csv('../UW_Madison/inputs/subjects.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the assigned grade counts to assigned grade percentages\n",
    "\n",
    "graded_students_count = (grades['a_count'] + grades['ab_count']+ grades['b_count'] + grades['bc_count']\n",
    "                      + grades['c_count'] + grades['d_count'] + grades['f_count'])\n",
    "\n",
    "percent_A = grades['a_count']/graded_students_count\n",
    "percent_AB = grades['ab_count']/graded_students_count\n",
    "percent_B = grades['b_count']/graded_students_count\n",
    "percent_BC = grades['bc_count']/graded_students_count\n",
    "percent_C = grades['c_count']/graded_students_count\n",
    "percent_D = grades['d_count']/graded_students_count\n",
    "percent_F = grades['f_count']/graded_students_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe of grade percentages for each course section offered\n",
    "\n",
    "uw_section_grades = pd.DataFrame()\n",
    "\n",
    "uw_section_grades['course_offering_uuid'] = grades['course_offering_uuid']\n",
    "uw_section_grades['percent_a'] = percent_A\n",
    "uw_section_grades['percent_ab'] = percent_AB\n",
    "uw_section_grades['percent_b'] = percent_B\n",
    "uw_section_grades['percent_bc'] = percent_BC\n",
    "uw_section_grades['percent_c'] = percent_C\n",
    "uw_section_grades['percent_d'] = percent_D\n",
    "uw_section_grades['percent_f'] = percent_F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_a</th>\n",
       "      <th>percent_ab</th>\n",
       "      <th>percent_b</th>\n",
       "      <th>percent_bc</th>\n",
       "      <th>percent_c</th>\n",
       "      <th>percent_d</th>\n",
       "      <th>percent_f</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course_offering_uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>344b3ebe-da7e-314c-83ed-9425269695fd</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f718e6cd-33f0-3c14-a9a6-834d9c3610a8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n",
       "      <td>0.891026</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>075da420-5f49-3dd0-93df-13e3c152e1b1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2b4e216d-a728-3713-8c7c-19afffc6b2fd</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      percent_a  percent_ab  percent_b  \\\n",
       "course_offering_uuid                                                     \n",
       "344b3ebe-da7e-314c-83ed-9425269695fd   1.000000    0.000000   0.000000   \n",
       "f718e6cd-33f0-3c14-a9a6-834d9c3610a8   1.000000    0.000000   0.000000   \n",
       "ea3b717c-d66b-30dc-8b37-964d9688295f   0.891026    0.076923   0.012821   \n",
       "075da420-5f49-3dd0-93df-13e3c152e1b1   1.000000    0.000000   0.000000   \n",
       "2b4e216d-a728-3713-8c7c-19afffc6b2fd   1.000000    0.000000   0.000000   \n",
       "\n",
       "                                      percent_bc  percent_c  percent_d  \\\n",
       "course_offering_uuid                                                     \n",
       "344b3ebe-da7e-314c-83ed-9425269695fd         0.0   0.000000        0.0   \n",
       "f718e6cd-33f0-3c14-a9a6-834d9c3610a8         0.0   0.000000        0.0   \n",
       "ea3b717c-d66b-30dc-8b37-964d9688295f         0.0   0.019231        0.0   \n",
       "075da420-5f49-3dd0-93df-13e3c152e1b1         0.0   0.000000        0.0   \n",
       "2b4e216d-a728-3713-8c7c-19afffc6b2fd         0.0   0.000000        0.0   \n",
       "\n",
       "                                      percent_f  \n",
       "course_offering_uuid                             \n",
       "344b3ebe-da7e-314c-83ed-9425269695fd        0.0  \n",
       "f718e6cd-33f0-3c14-a9a6-834d9c3610a8        0.0  \n",
       "ea3b717c-d66b-30dc-8b37-964d9688295f        0.0  \n",
       "075da420-5f49-3dd0-93df-13e3c152e1b1        0.0  \n",
       "2b4e216d-a728-3713-8c7c-19afffc6b2fd        0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uw_section_grades.set_index('course_offering_uuid', drop = True, inplace = True)\n",
    "uw_section_grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And eliminating any course sections for which no student received a letter grade\n",
    "# This ends up being roughly half of the total sections\n",
    "\n",
    "uw_section_grades.dropna(axis = 0, how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Associating subjects to each class\n",
    "\n",
    "The University of Wisconsin has many classes that are cross-listed, that is, they are taught across multiple departments. Thus, my next step was to construct a dictionary with an entry for each course section which contained a list of all of the departments to which it belongs.  These lists can range from a single department up to ten, or even more. \n",
    "\n",
    "I then converted the resulting dictionary into a dataframe and merged it with my grades data in order to assure that the order of my sets of observations was identical.\n",
    "\n",
    "Finally, I split the data into two numpy arrays, the first ```grades``` containing all of the percentages of grades for each course section, and the second ```subjects``` containing all of the assigned subjects for each course section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dict = {}\n",
    "\n",
    "for i in range(len(subject_mems)):\n",
    "    code = subject_mems.loc[i, 'course_offering_uuid']\n",
    "    if code not in subjects_dict.keys():\n",
    "        subjects_dict[code] = [subject_mems.loc[i, 'subject_code']]\n",
    "    else:\n",
    "        subjects_dict[code].append(subject_mems.loc[i, 'subject_code'])\n",
    "        \n",
    "max_subjects = 1\n",
    "for key in subjects_dict.keys():\n",
    "    if len(subjects_dict[key]) > max_subjects:\n",
    "        max_subjects = len(subjects_dict[key])\n",
    "        \n",
    "cols = []\n",
    "for j in range(max_subjects):\n",
    "    cols.append('Suj' + str(j))\n",
    "        \n",
    "consolidated_subject_mems = pd.DataFrame.from_dict(subjects_dict, orient = 'index', columns = cols)\n",
    "\n",
    "cols = ['course_offering_uuid']\n",
    "cols.extend(consolidated_subject_mems.columns.tolist())\n",
    "\n",
    "consolidated_subject_mems.reset_index(inplace = True, drop = False)\n",
    "consolidated_subject_mems.columns = cols\n",
    "\n",
    "consolidated_subject_mems.set_index('course_offering_uuid', drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suj0</th>\n",
       "      <th>Suj1</th>\n",
       "      <th>Suj2</th>\n",
       "      <th>Suj3</th>\n",
       "      <th>Suj4</th>\n",
       "      <th>Suj5</th>\n",
       "      <th>Suj6</th>\n",
       "      <th>Suj7</th>\n",
       "      <th>Suj8</th>\n",
       "      <th>Suj9</th>\n",
       "      <th>Suj10</th>\n",
       "      <th>Suj11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course_offering_uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>344b3ebe-da7e-314c-83ed-9425269695fd</td>\n",
       "      <td>220</td>\n",
       "      <td>320.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f718e6cd-33f0-3c14-a9a6-834d9c3610a8</td>\n",
       "      <td>220</td>\n",
       "      <td>320.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n",
       "      <td>220</td>\n",
       "      <td>320.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>075da420-5f49-3dd0-93df-13e3c152e1b1</td>\n",
       "      <td>220</td>\n",
       "      <td>320.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2b4e216d-a728-3713-8c7c-19afffc6b2fd</td>\n",
       "      <td>220</td>\n",
       "      <td>320.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Suj0   Suj1   Suj2   Suj3   Suj4   Suj5  \\\n",
       "course_offering_uuid                                                            \n",
       "344b3ebe-da7e-314c-83ed-9425269695fd   220  320.0  346.0  612.0  636.0  207.0   \n",
       "f718e6cd-33f0-3c14-a9a6-834d9c3610a8   220  320.0  346.0  612.0  636.0  207.0   \n",
       "ea3b717c-d66b-30dc-8b37-964d9688295f   220  320.0  684.0  346.0  612.0  207.0   \n",
       "075da420-5f49-3dd0-93df-13e3c152e1b1   220  320.0  346.0  612.0  207.0  636.0   \n",
       "2b4e216d-a728-3713-8c7c-19afffc6b2fd   220  320.0  684.0  346.0  612.0  207.0   \n",
       "\n",
       "                                       Suj6   Suj7   Suj8   Suj9  Suj10  Suj11  \n",
       "course_offering_uuid                                                            \n",
       "344b3ebe-da7e-314c-83ed-9425269695fd  490.0  240.0    NaN    NaN    NaN    NaN  \n",
       "f718e6cd-33f0-3c14-a9a6-834d9c3610a8  490.0  418.0  240.0    NaN    NaN    NaN  \n",
       "ea3b717c-d66b-30dc-8b37-964d9688295f  636.0  490.0  418.0  240.0    NaN    NaN  \n",
       "075da420-5f49-3dd0-93df-13e3c152e1b1  490.0  240.0    NaN    NaN    NaN    NaN  \n",
       "2b4e216d-a728-3713-8c7c-19afffc6b2fd  636.0  490.0  240.0    NaN    NaN    NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_subject_mems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_section_grades = pd.merge(uw_section_grades, consolidated_subject_mems,\n",
    "                           how='left', left_index = True,right_index =True, sort=False,\n",
    "                           copy=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87209"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uw_section_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_a</th>\n",
       "      <th>percent_ab</th>\n",
       "      <th>percent_b</th>\n",
       "      <th>percent_bc</th>\n",
       "      <th>percent_c</th>\n",
       "      <th>percent_d</th>\n",
       "      <th>percent_f</th>\n",
       "      <th>Suj0</th>\n",
       "      <th>Suj1</th>\n",
       "      <th>Suj2</th>\n",
       "      <th>Suj3</th>\n",
       "      <th>Suj4</th>\n",
       "      <th>Suj5</th>\n",
       "      <th>Suj6</th>\n",
       "      <th>Suj7</th>\n",
       "      <th>Suj8</th>\n",
       "      <th>Suj9</th>\n",
       "      <th>Suj10</th>\n",
       "      <th>Suj11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course_offering_uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>000085b6-0eb9-386e-881e-60cc62be5b62</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00015734-b612-3152-bf5f-7f6855e1c0c0</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0002389b-0bda-3f47-b5e7-e9d8973cb2e9</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00028b06-6e42-3a3e-b484-69fd61baf978</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00049821-be2e-3e8e-b697-848621267154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0005d259-9986-3184-b638-e0f23ed55040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0006b3f8-3403-35d5-bda2-9489e3c84434</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000967ae-98da-36b7-888a-cfcf87c571e5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>864</td>\n",
       "      <td>900.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000967ae-98da-36b7-888a-cfcf87c571e5</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>864</td>\n",
       "      <td>900.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00098cbe-d97f-3b05-b976-e67a6efdecbf</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>418</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      percent_a  percent_ab  percent_b  \\\n",
       "course_offering_uuid                                                     \n",
       "000085b6-0eb9-386e-881e-60cc62be5b62   1.000000    0.000000   0.000000   \n",
       "00015734-b612-3152-bf5f-7f6855e1c0c0   0.294118    0.223529   0.164706   \n",
       "0002389b-0bda-3f47-b5e7-e9d8973cb2e9   0.636364    0.363636   0.000000   \n",
       "00028b06-6e42-3a3e-b484-69fd61baf978   0.444444    0.148148   0.333333   \n",
       "00049821-be2e-3e8e-b697-848621267154   1.000000    0.000000   0.000000   \n",
       "0005d259-9986-3184-b638-e0f23ed55040   1.000000    0.000000   0.000000   \n",
       "0006b3f8-3403-35d5-bda2-9489e3c84434   0.730769    0.115385   0.076923   \n",
       "000967ae-98da-36b7-888a-cfcf87c571e5   0.250000    0.458333   0.208333   \n",
       "000967ae-98da-36b7-888a-cfcf87c571e5   0.391304    0.260870   0.130435   \n",
       "00098cbe-d97f-3b05-b976-e67a6efdecbf   0.333333    0.333333   0.250000   \n",
       "\n",
       "                                      percent_bc  percent_c  percent_d  \\\n",
       "course_offering_uuid                                                     \n",
       "000085b6-0eb9-386e-881e-60cc62be5b62    0.000000   0.000000   0.000000   \n",
       "00015734-b612-3152-bf5f-7f6855e1c0c0    0.105882   0.188235   0.023529   \n",
       "0002389b-0bda-3f47-b5e7-e9d8973cb2e9    0.000000   0.000000   0.000000   \n",
       "00028b06-6e42-3a3e-b484-69fd61baf978    0.037037   0.000000   0.037037   \n",
       "00049821-be2e-3e8e-b697-848621267154    0.000000   0.000000   0.000000   \n",
       "0005d259-9986-3184-b638-e0f23ed55040    0.000000   0.000000   0.000000   \n",
       "0006b3f8-3403-35d5-bda2-9489e3c84434    0.038462   0.038462   0.000000   \n",
       "000967ae-98da-36b7-888a-cfcf87c571e5    0.083333   0.000000   0.000000   \n",
       "000967ae-98da-36b7-888a-cfcf87c571e5    0.173913   0.043478   0.000000   \n",
       "00098cbe-d97f-3b05-b976-e67a6efdecbf    0.083333   0.000000   0.000000   \n",
       "\n",
       "                                      percent_f  Suj0   Suj1   Suj2  Suj3  \\\n",
       "course_offering_uuid                                                        \n",
       "000085b6-0eb9-386e-881e-60cc62be5b62        0.0   736    NaN    NaN   NaN   \n",
       "00015734-b612-3152-bf5f-7f6855e1c0c0        0.0   224    NaN    NaN   NaN   \n",
       "0002389b-0bda-3f47-b5e7-e9d8973cb2e9        0.0   544    NaN    NaN   NaN   \n",
       "00028b06-6e42-3a3e-b484-69fd61baf978        0.0   224    NaN    NaN   NaN   \n",
       "00049821-be2e-3e8e-b697-848621267154        0.0   938    NaN    NaN   NaN   \n",
       "0005d259-9986-3184-b638-e0f23ed55040        0.0   938    NaN    NaN   NaN   \n",
       "0006b3f8-3403-35d5-bda2-9489e3c84434        0.0   896    NaN    NaN   NaN   \n",
       "000967ae-98da-36b7-888a-cfcf87c571e5        0.0   864  900.0  271.0   NaN   \n",
       "000967ae-98da-36b7-888a-cfcf87c571e5        0.0   864  900.0  271.0   NaN   \n",
       "00098cbe-d97f-3b05-b976-e67a6efdecbf        0.0   418  240.0    NaN   NaN   \n",
       "\n",
       "                                      Suj4  Suj5  Suj6  Suj7  Suj8  Suj9  \\\n",
       "course_offering_uuid                                                       \n",
       "000085b6-0eb9-386e-881e-60cc62be5b62   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "00015734-b612-3152-bf5f-7f6855e1c0c0   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "0002389b-0bda-3f47-b5e7-e9d8973cb2e9   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "00028b06-6e42-3a3e-b484-69fd61baf978   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "00049821-be2e-3e8e-b697-848621267154   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "0005d259-9986-3184-b638-e0f23ed55040   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "0006b3f8-3403-35d5-bda2-9489e3c84434   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "000967ae-98da-36b7-888a-cfcf87c571e5   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "000967ae-98da-36b7-888a-cfcf87c571e5   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "00098cbe-d97f-3b05-b976-e67a6efdecbf   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "                                      Suj10  Suj11  \n",
       "course_offering_uuid                                \n",
       "000085b6-0eb9-386e-881e-60cc62be5b62    NaN    NaN  \n",
       "00015734-b612-3152-bf5f-7f6855e1c0c0    NaN    NaN  \n",
       "0002389b-0bda-3f47-b5e7-e9d8973cb2e9    NaN    NaN  \n",
       "00028b06-6e42-3a3e-b484-69fd61baf978    NaN    NaN  \n",
       "00049821-be2e-3e8e-b697-848621267154    NaN    NaN  \n",
       "0005d259-9986-3184-b638-e0f23ed55040    NaN    NaN  \n",
       "0006b3f8-3403-35d5-bda2-9489e3c84434    NaN    NaN  \n",
       "000967ae-98da-36b7-888a-cfcf87c571e5    NaN    NaN  \n",
       "000967ae-98da-36b7-888a-cfcf87c571e5    NaN    NaN  \n",
       "00098cbe-d97f-3b05-b976-e67a6efdecbf    NaN    NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uw_section_grades.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = np.array(uw_section_grades[['percent_a', 'percent_ab', 'percent_b', 'percent_bc',\n",
    "                            'percent_c', 'percent_d', 'percent_f']])\n",
    "\n",
    "subjects = np.array(uw_section_grades[['Suj0', 'Suj1', 'Suj2', 'Suj3', 'Suj4', 'Suj5', \n",
    "                                       'Suj6', 'Suj7', 'Suj8', 'Suj9', 'Suj10', 'Suj11']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.29411765, 0.22352941, 0.16470588, 0.10588235, 0.18823529,\n",
       "        0.02352941, 0.        ],\n",
       "       [0.63636364, 0.36363636, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.44444444, 0.14814815, 0.33333333, 0.03703704, 0.        ,\n",
       "        0.03703704, 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the k means clustering model\n",
    "\n",
    "In order to construct a model for k means, I built a series of functions.\n",
    "- ```euclid_dist``` computes the Euclidean distance between two points in $\\mathbb{R}^n$,\n",
    "- ```assign_center``` takes an observation and determines which of our current cluster centers it is closest to, then assigns it to that cluster,\n",
    "- ```compute_centers``` takes an array of observations along with their assigned clusters and computes the center of each current cluster,\n",
    "- ```k_means_centers``` randomly selects k points from an array of observations as initial cluster centers, then iterates ```assign_center``` and ```compute_centers``` until the cluster centers converge,\n",
    "- ```internal_dist``` computes the sum of the total pairwise internal distance among observations in each cluster, and\n",
    "- ```best_kmeans``` calls ```k_means_centers``` repeatedly and returns the list of cluster centers that was obtained by the best performing iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_dist(p1, p2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the Euclidean distance between two points in  R^n\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p1 : list or numpy array\n",
    "        A point in R^n\n",
    "    p2 : list or numpy array\n",
    "        A second point in R^n\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The Euclidean distance between the two points\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    v1 = np.array(p1)\n",
    "    v2 = np.array(p2)\n",
    "    \n",
    "    diff_squared = (v1 - v2) ** 2\n",
    "    \n",
    "    dist = np.sqrt(np.sum(diff_squared))\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_center(p1, centers): # p1 is list or np array, centers is dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes an observation and determines to which of our current cluster centers it is closest, \n",
    "    then assigns it to that cluster\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p1 : numpy array \n",
    "        An observation\n",
    "    centers : dictionary\n",
    "        The centers of our current clusters \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The key of the closest cluster center\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    current_closest = -1\n",
    "    current_dist = np.inf\n",
    "\n",
    "    for key in centers.keys():\n",
    "        new_dist = euclid_dist(p1, centers[key])\n",
    "        if new_dist < current_dist:\n",
    "            current_closest = key\n",
    "            current_dist = new_dist\n",
    "    \n",
    "    return current_closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centers(da, assignments, k):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes an array of observations along with their assigned clusters and \n",
    "    computes the center of each current cluster\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : numpy array \n",
    "        The observations on which we are basing our model\n",
    "    assignments : list\n",
    "        The assigned cluster for each observation\n",
    "    k : int\n",
    "        The number of clusters in the current model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dictionary\n",
    "        The new centers for the clusters\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    new_centers = {}\n",
    "    \n",
    "    for i in range(k):\n",
    "        \n",
    "        # retrieve the points assigned to the given group\n",
    "        \n",
    "        mask = [assignments[j] == i for j in range(len(assignments))]\n",
    "        grouped_points = da[mask, :]\n",
    "        \n",
    "        if grouped_points.shape[0] > 0:\n",
    "        # compute the center of that group\n",
    "        \n",
    "            mean = np.mean(grouped_points, axis = 0)\n",
    "        \n",
    "            new_centers[i] = mean\n",
    "        else:\n",
    "            random_index = random.sample(list(range(da.shape[0])), 1) \n",
    "            new_centers[i] = da[random_index]\n",
    "        \n",
    "    return new_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_centers(da, k, epsilon = 0.001):\n",
    "    \n",
    "    \"\"\"\n",
    "    Randomly selects k points from an array of observations as initial cluster centers, \n",
    "    then iterates ```assign_center``` and ```compute_centers``` until the cluster centers converge\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : numpy array \n",
    "        The observations on which we are basing our model\n",
    "    k : int\n",
    "        The number of clusters we are creating\n",
    "    epsilon : float\n",
    "        Controls at what point the algorithm is said to have converged, default value = 0.001\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dictionary\n",
    "        The cluster centers after the algorithm has converged\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Randomly choose k initial centers\n",
    "    \n",
    "    center_indices = random.sample(list(range(da.shape[0])), k)\n",
    "        \n",
    "    centers = {}\n",
    "    for i in range(len(center_indices)):\n",
    "        centers[i] = da[center_indices[i], :]\n",
    "        \n",
    "    keep_going = True\n",
    "      \n",
    "    rounds = 0\n",
    "    while keep_going == True:\n",
    "        rounds += 1\n",
    "        # Assign each point to the closest center\n",
    "    \n",
    "        assignments = [-1 for i in range(da.shape[0])]\n",
    "        for i in range(da.shape[0]):\n",
    "            assignments[i] = assign_center(da[i, :], centers)\n",
    "    \n",
    "        # Compute the center of each chunk\n",
    "    \n",
    "        new_centers = compute_centers(da, assignments, k)\n",
    "    \n",
    "        # Compute the total distance that the centers have moved\n",
    "    \n",
    "        distance_moved = 0\n",
    "        for key in centers.keys():\n",
    "            distance_moved += euclid_dist(centers[key], new_centers[key])\n",
    "            \n",
    "        if distance_moved > epsilon:\n",
    "            centers = new_centers\n",
    "        else:\n",
    "            keep_going = False\n",
    "    \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internal_dist(da, centers):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the sum of the total pairwise internal distance among observations in each cluster\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : numpy array \n",
    "        The observations on which we are basing our model\n",
    "    centers : dictionary\n",
    "        The centers of our current clusters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The total internal distance for all of the current clusters\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    total_distance = 0\n",
    "    assignments = [-1 for i in range(da.shape[0])]\n",
    "    for i in range(da.shape[0]):\n",
    "        assignments[i] = assign_center(da[i], centers)\n",
    "        \n",
    "    for key in centers.keys():\n",
    "        mask = [assignments[k] == key for k in range(len(assignments))]\n",
    "        grouped_points = da[mask]\n",
    "        \n",
    "        group_distance = 0\n",
    "        for j in range(grouped_points.shape[0]):\n",
    "            for k in range(grouped_points.shape[0]):\n",
    "                group_distance += euclid_dist(grouped_points[j], grouped_points[k])\n",
    "        \n",
    "        total_distance += group_distance\n",
    "\n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_kmeans(da, k, n = 3, epsilon = 0.001):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calls ```k_means_centers``` repeatedly and returns the list of \n",
    "    cluster centers that was obtained by the best performing iteration\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : numpy array \n",
    "        The observations on which we are basing our model\n",
    "    k : int\n",
    "        The number of clusters we are creating\n",
    "    n : int\n",
    "        The number of models to build and compare\n",
    "    epsilon : float\n",
    "        Controls at what point the algorithm is said to have converged, default value = 0.001\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The reduction (if positive) or increase (if negative) in the impurity with the specified split\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    best_dist = np.inf\n",
    "    best_centers = {}\n",
    "    \n",
    "    for i in range(n):\n",
    "        centers = kmeans_centers(da, k, epsilon)\n",
    "        dist = internal_dist(da, centers)\n",
    "        if dist < best_dist:\n",
    "            best_dist = dist\n",
    "            best_centers = centers\n",
    "            \n",
    "    return best_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a model to our grades data\n",
    "\n",
    "Due to the size of our data set (nearly 90 000 observations), we fit our model on a random sample of size 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.sample(list(range(grades.shape[0])), 5000)\n",
    "sampled = grades[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = best_kmeans(sampled, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.50341434, 0.15205297, 0.23667483, 0.04300628, 0.0454299 ,\n",
       "        0.01009001, 0.00933166]),\n",
       " 1: array([0.16221663, 0.33506411, 0.36633835, 0.08644442, 0.03577865,\n",
       "        0.00825849, 0.00589934]),\n",
       " 2: array([0.27108101, 0.54121236, 0.13527558, 0.02874053, 0.01543891,\n",
       "        0.00467976, 0.00357184]),\n",
       " 3: array([0.20849883, 0.13624864, 0.27956597, 0.13708489, 0.16898335,\n",
       "        0.04424513, 0.02537319]),\n",
       " 4: array([0.51166991, 0.3784247 , 0.07353292, 0.01974098, 0.00931554,\n",
       "        0.00360621, 0.00370973]),\n",
       " 5: array([0.2392817 , 0.07582715, 0.5777588 , 0.03531778, 0.057615  ,\n",
       "        0.00882902, 0.00537056]),\n",
       " 6: array([0.84934366, 0.09138226, 0.03879665, 0.00762495, 0.00713333,\n",
       "        0.00212931, 0.00358983]),\n",
       " 7: array([0.33289192, 0.29833688, 0.22901418, 0.07862603, 0.03859912,\n",
       "        0.01253314, 0.00999873]),\n",
       " 8: array([0.69334177, 0.2195652 , 0.05784988, 0.01266468, 0.00874554,\n",
       "        0.00341936, 0.00441355]),\n",
       " 9: array([9.90431470e-01, 4.32021127e-03, 3.29813258e-03, 5.16434826e-04,\n",
       "        5.26766668e-04, 3.49212694e-04, 5.57772022e-04])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning subjects to clusters\n",
    "\n",
    "In order to assign subjects to clusters, I constructed the following functions:\n",
    "- ```subjects_by_asst``` produces a dictionary of frequencies for each subject code associated to a class found in a specified cluster, \n",
    "- ```subject_clusters``` assigns each subject code to the cluster for which it has the highest frequency\n",
    "- ```subject_name_clusters``` creates a dictionary of subject names associated to each cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjects_by_asst(assignments, asst, da):\n",
    "    \n",
    "    \"\"\"\n",
    "    Produces a dictionary of frequencies for each subject code associated to a class\n",
    "    found in a specified cluster\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    assignments : list \n",
    "        The cluster to which each observation is assigned\n",
    "    asst : int\n",
    "        The number of the cluster under consideration\n",
    "    da : numpy array\n",
    "        The subject assignments for each course section\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The number of occurances of each subject code for course sections assigned\n",
    "        to the given cluster\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    assignment_mask = [assignments[i] == asst for i in range(len(assignments))]\n",
    "    subjects = da[assignment_mask].tolist()\n",
    "    \n",
    "    subject_list = [item for sublist in subjects for item in sublist if str(item) != 'nan']\n",
    "    \n",
    "    my_subject_dict = defaultdict(int)\n",
    "    for item in subject_list:\n",
    "        my_subject_dict[item] += 1\n",
    "    \n",
    "    return my_subject_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_clusters(centers, da, subjects):\n",
    "    \n",
    "    \"\"\"\n",
    "    Assigns each subject code to the cluster for which it has the highest frequency\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    centers : dictionary \n",
    "        The centers of our current clusters\n",
    "    da : numpy array\n",
    "        The observations on which we are basing our model\n",
    "    subjects: numpy array\n",
    "        The subject codes assigned to each course section\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas dataframe\n",
    "        The cluster most associated to each subject code\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # First assign each observation in the dataset to a center\n",
    "    \n",
    "    assignments = [-1 for i in range(grades.shape[0])]\n",
    "    for i in range(da.shape[0]):\n",
    "        assignments[i] = assign_center(da[i, :], centers)\n",
    "        \n",
    "    # Second, create a dictionary of dictionaries of subject counts assigned to each cluster\n",
    "    \n",
    "    subject_cluster_dicts = {}\n",
    "    \n",
    "    for i in range(len(centers)):\n",
    "        subject_cluster_dicts[i] = subjects_by_asst(assignments, i, subjects)\n",
    "        \n",
    "    # Third, create a list of keys across all dictionaries in subject_cluster_dicts\n",
    "    \n",
    "    subject_keys = []\n",
    "    \n",
    "    for i in subject_cluster_dicts.keys():\n",
    "        subject_keys.extend(subject_cluster_dicts[i].keys())\n",
    "        \n",
    "    # And now assign each key to a cluster based on which cluster it occurs in most frequently\n",
    "    \n",
    "    subject_cluster_asst = pd.DataFrame()\n",
    "\n",
    "    for key in subject_keys:\n",
    "        cluster_count = [subject_cluster_dicts[i][key] for i in subject_cluster_dicts.keys()]\n",
    "        subject_cluster_asst.loc[key, 'assignment'] = np.argmax(cluster_count)\n",
    "        \n",
    "    subject_cluster_asst.reset_index(inplace = True)\n",
    "    \n",
    "    return subject_cluster_asst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_assignments = subject_clusters(centers, grades, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_names.drop(\n",
    "    [subject_names.loc[(subject_names['code'] == 'ZZZ')].index.tolist()[0], \n",
    "     subject_names.loc[(subject_names['code'] == 'SAB')].index.tolist()[0]],\n",
    "inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_names = subject_names.astype({'code': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code             int32\n",
       "name            object\n",
       "abbreviation    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_names.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_names.set_index('code', drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_name_clusters(subject_assignments, subject_names):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates a dictionary of subject names associated to each cluster\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subject_assignments : pandas dataframe \n",
    "        Associates a cluster to each subject code\n",
    "    subject_names : pandas dataframe\n",
    "        Associates a subject name to each subject code\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dictionary\n",
    "        The subject names associated with each cluster\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    subject_clusters = {}\n",
    "    \n",
    "    possible_assignments = list(set(subject_assignments['assignment']))\n",
    "    \n",
    "    for asst in possible_assignments:\n",
    "        subjects_assigned = list(subject_assignments.loc[subject_assignments['assignment'] == asst]['index'])\n",
    "        cluster_subjects = list(subject_names.loc[subjects_assigned, 'name'])\n",
    "        subject_clusters[asst] = cluster_subjects\n",
    "        \n",
    "    return subject_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_clusters = subject_name_clusters(subject_assignments, subject_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I want to examine the subject clusters that I've produced and the cluster centers that go with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50341434 0.15205297 0.23667483 0.04300628 0.0454299  0.01009001\n",
      " 0.00933166]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Molecular and Environmental Toxicology Center',\n",
       " 'Pathology and Laboratory Medicine',\n",
       " 'East Asian Area Studies',\n",
       " 'Portuguese (Spanish and Portuguese)',\n",
       " 'Latin (Classics)',\n",
       " 'ANIMAL HEALTH AND BIOMEDICAL SCIENCES',\n",
       " 'Agronomy',\n",
       " 'German',\n",
       " 'Comparative Biosciences',\n",
       " 'Greek (Classics)',\n",
       " 'TRANSPORTATION AND PUBLIC UTILITIES']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(centers[0])\n",
    "subject_clusters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For cluster 0.0 we have:\n",
      "        The cluster center is  [0.50341434 0.15205297 0.23667483 0.04300628 0.0454299  0.01009001\n",
      " 0.00933166]\n",
      "        The cluster subjects are ['ANIMAL HEALTH AND BIOMEDICAL SCIENCES', 'Agronomy', 'Comparative Biosciences', 'East Asian Area Studies', 'German', 'Greek (Classics)', 'Latin (Classics)', 'Molecular and Environmental Toxicology Center', 'Pathology and Laboratory Medicine', 'Portuguese (Spanish and Portuguese)', 'TRANSPORTATION AND PUBLIC UTILITIES']\n",
      "===========\n",
      "For cluster 1.0 we have:\n",
      "        The cluster center is  [0.16221663 0.33506411 0.36633835 0.08644442 0.03577865 0.00825849\n",
      " 0.00589934]\n",
      "        The cluster subjects are ['CLINICAL LABORATORY SCIENCE', 'Communication Arts', 'Legal Studies', 'Marketing', 'Senior Medical Program']\n",
      "===========\n",
      "For cluster 2.0 we have:\n",
      "        The cluster center is  [0.27108101 0.54121236 0.13527558 0.02874053 0.01543891 0.00467976\n",
      " 0.00357184]\n",
      "        The cluster subjects are ['Engineering Professional Development', 'Jewish Studies', 'Pediatrics', 'Physician Assistant Program', 'Psychiatry']\n",
      "===========\n",
      "For cluster 3.0 we have:\n",
      "        The cluster center is  [0.20849883 0.13624864 0.27956597 0.13708489 0.16898335 0.04424513\n",
      " 0.02537319]\n",
      "        The cluster subjects are ['Accounting and Information Systems', 'Agricultural and Applied Economics', 'Anthropology', 'Astronomy', 'Atmospheric and Oceanic Sciences', 'Biological Systems Engineering', 'Biology', 'Botany', 'Chemical and Biological Engineering', 'Chemistry', 'Computer Sciences', 'Economics', 'Electrical and Computer Engineering', 'Engineering Mechanics and Astronautics', 'Food Science', 'Geological Engineering', 'Geoscience', 'Mathematics', 'Mechanical Engineering', 'Nutritional Sciences', 'Physics', 'Statistics', 'WILDLIFE ECOLOGY', 'Zoology']\n",
      "===========\n",
      "For cluster 4.0 we have:\n",
      "        The cluster center is  [0.51166991 0.3784247  0.07353292 0.01974098 0.00931554 0.00360621\n",
      " 0.00370973]\n",
      "        The cluster subjects are ['Asian American Studies', 'Biomedical Engineering', 'Comparative Literature', 'ENGLISH', 'Emergency Medicine', 'French (French and Italian)', 'Gender and Women’s Studies', 'Human Oncology', 'Interdisciplinary Courses (Engineering)', 'Journalism and Mass Communication', 'La Follette School of Public Affairs', 'Latin American, Caribbean, and Iberian Studies', 'Management and Human Resources', 'Medical Physics', 'Scandinavian Studies']\n",
      "===========\n",
      "For cluster 5.0 we have:\n",
      "        The cluster center is  [0.2392817  0.07582715 0.5777588  0.03531778 0.057615   0.00882902\n",
      " 0.00537056]\n",
      "        The cluster subjects are ['Biology Core Curriculum', 'Law']\n",
      "===========\n",
      "For cluster 6.0 we have:\n",
      "        The cluster center is  [0.84934366 0.09138226 0.03879665 0.00762495 0.00713333 0.00212931\n",
      " 0.00358983]\n",
      "        The cluster subjects are ['Air Force Aerospace Studies', 'Consumer Science', 'Dance', 'Engineering Physics', 'General Business', 'Interdisciplinary Courses (CALS)', 'Interdisciplinary Courses (L&S)', 'Interdisciplinary Courses (SOHE)', 'Languages and Cultures of Asia - Languages', 'PROFESSIONAL ORIENTATION']\n",
      "===========\n",
      "For cluster 7.0 we have:\n",
      "        The cluster center is  [0.33289192 0.29833688 0.22901418 0.07862603 0.03859912 0.01253314\n",
      " 0.00999873]\n",
      "        The cluster subjects are ['Actuarial Science', 'Afro-American Studies', 'Art History', 'Chicana/o and Latina/o Studies', 'Classics', 'Community and Environmental Sociology', 'English as a Second Language', 'Farm & Industry Short Course', 'Finance, Investment and Banking', 'Forest and Wildlife Ecology', 'Geography', 'History', 'History of Science', 'Horticulture', 'International Studies', 'Italian (French and Italian)', 'Landscape Architecture', 'Languages and Cultures of Asia', 'Linguistics', 'Literature in Translation', 'Medical History and Bioethics', 'Medical Sciences - Medical School', 'Medieval Studies', 'Nuclear Engineering', 'Operations and Technology Management', 'Philosophy', 'Plant Pathology', 'Political Science', 'Real Estate and Urban Land Economics', 'Religious Studies', 'Risk Management and Insurance', 'Sociology', 'Soil Science', 'Spanish (Spanish and Portuguese)']\n",
      "===========\n",
      "For cluster 8.0 we have:\n",
      "        The cluster center is  [0.69334177 0.2195652  0.05784988 0.01266468 0.00874554 0.00341936\n",
      " 0.00441355]\n",
      "        The cluster subjects are ['African Languages and Literature', 'American Indian Studies', 'Civil Society and Community Studies', 'Collaborative Nursing Program', 'Design Studies', 'East Asian Languages and Literature', 'FAMILY AND CONSUMER COMMUNICATIONS', 'Folklore Program', 'HEBREW', 'Human Development and Family Studies', 'INDUSTRIAL RELATIONS', 'Information Systems', 'Integrated Arts', 'Life Sciences Communication', 'PHYSICAL EDUC ACTIVITY PROGM', 'Pharmacy', 'Radiology', 'Slavic (Slavic Languages)']\n",
      "===========\n",
      "For cluster 9.0 we have:\n",
      "        The cluster center is  [9.90431470e-01 4.32021127e-03 3.29813258e-03 5.16434826e-04\n",
      " 5.26766668e-04 3.49212694e-04 5.57772022e-04]\n",
      "        The cluster subjects are ['Agroecology', 'Anatomy', 'Anesthesiology', 'Animal Sciences', 'Art Department', 'Art Education (Department of Art)', 'Biochemistry', 'Biomolecular Chemistry', 'Biostatistics and Medical Informatics', 'Cell and Regenerative Biology', 'Civil and Environmental Engineering', 'Communication Sciences and Disorders', 'Counseling Psychology', 'Curriculum and Instruction', 'Dairy Science', 'Educational Leadership and Policy Analysis', 'Educational Policy Studies', 'Educational Psychology', 'English', 'Entomology', 'Environmental Studies - Gaylord Nelson Institute', 'Family Medicine', 'Genetics', 'Hebrew-Modern', 'Industrial and Systems Engineering', 'Integrated Liberal Studies', 'Integrated Science', 'International Business', 'Kinesiology', 'Library and Information Studies', 'Materials Science and Engineering', 'Medical Genetics', 'Medical Microbiology and Immunology', 'Medical Sciences - Veterinary Medicine', 'Medicine', 'Microbiology', 'Military Science', 'Molecular Biology', 'Music', 'Music-Performance', 'Naval Science', 'Neurological Surgery', 'Neurology', 'Neuroscience', 'Neuroscience Training Program', 'Nursing', 'Obstetrics and Gynecology', 'Occupational Therapy (Department of Kinesiology)', 'Oncology', 'Ophthalmology and Visual Sciences', 'Patho-Biological Sciences', 'Pharmaceutical Sciences', 'Pharmacology', 'Pharmacy Practice', 'Physical Therapy', 'Physiology', 'Population Health Sciences', 'Psychology', 'Rehabilitation Psychology and Special Education', 'Science and Technology Studies', 'Social Work', 'Social and Administrative Pharmacy', 'Surgery', 'Surgical Sciences', 'Theatre and Drama', 'Therapeutic Science (Department of Kinesiology)', 'Urban and Regional Planning']\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "for key in subject_clusters.keys():\n",
    "    print('For cluster {} we have:'.format(np.rint(key)))\n",
    "    print('        The cluster center is ', centers[key])\n",
    "    print('        The cluster subjects are', list(np.sort(subject_clusters[key])))\n",
    "    print('===========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Using the k means model that I produced, I found that there does indeed seem to be a relationship between grading severity and subject (or academic disciple) at the University of Wisconsin. The following table shows the subjects assigned to each cluster along with the grade values for the cluster center. The table is sorted from fewest As to most As as a fraction of total grades. Note that while some cluster centers had fewer than 25% assigned A grades, several had more than 50% assigned A grades, and one had a whopping 99% assigned A grades. Note also that only one cluster assigned more than 5% D or F grades, the second cluster, associated primarily with Engineering and the Sciences. By contrast, there are four clusters where fewer than 1% of enrolled students were assigned D or F grades. \n",
    "\n",
    "\n",
    "|A|AB|B|BC|C|D|F|Subjects|\n",
    "|-|--|-|--|-|-|-|:--------|\n",
    "|0.162| 0.335| 0.366| 0.086| 0.0358| 0.008| 0.006|<ul><li>Clinical Laboratory Science</li><li> Communication Arts</li><li> Legal Studies</li><li> Marketing</li><li> Senior Medical Program</li></ul>|\n",
    "|0.208| 0.136| 0.280| 0.137| 0.169| 0.044| 0.025|<ul><li> Accounting and Information Systems</li><li> Agricultural and Applied Economics</li><li> Anthropology</li><li> Astronomy</li><li> Atmospheric and Oceanic Sciences</li><li> Biological Systems Engineering</li><li> Biology</li><li> Botany</li><li> Chemical and Biological Engineering</li><li> Chemistry</li><li> Computer Sciences</li><li> Economics</li><li> Electrical and Computer Engineering</li><li> Engineering Mechanics and Astronautics</li><li> Food Science</li><li> Geological Engineering</li><li> Geoscience</li><li> Mathematics</li><li> Mechanical Engineering</li><li> Nutritional Sciences</li><li> Physics</li><li> Statistics</li><li> Wildlife Ecology</li><li> Zoology</li></ul>|\n",
    "|0.239| 0.076| 0.578|  0.035|0.058|   0.009| 0.005 |<ul><li>Biology Core Curriculum</li><li> Law</li></ul>|\n",
    "|0.271| 0.541| 0.135| 0.029| 0.015| 0.005| 0.004|<ul><li> Engineering Professional Development</li><li> Jewish Studies</li><li> Pediatrics</li><li> Physician Assistant Program</li><li> Psychiatry</li></ul>|\n",
    "|0.332| 0.298| 0.229| 0.079| 0.039| 0.013| 0.010|<ul><li> Actuarial Science</li><li> Afro-American Studies</li><li> Art History</li><li> Chicana/o and Latina/o Studies</li><li> Classics</li><li> Community and Environmental Sociology</li><li> English as a Second Language</li><li> Farm and Industry Short Course</li><li> Finance</li><li> Investment and Banking</li><li> Forest and Wildlife Ecology</li><li> Geography</li><li> History</li><li> History of Science</li><li> Horticulture</li><li> International Studies</li><li> Italian (French and Italian)</li><li> Landscape Architecture</li><li> Languages and Cultures of Asia</li><li> Linguistics</li><li> Literature in Translation</li><li> Medical History and Bioethics</li><li> Medical Sciences - Medical School</li><li> Medieval Studies</li><li> Nuclear Engineering</li><li> Operations and Technology Management</li><li> Philosophy</li><li> Plant Pathology</li><li> Political Science</li><li> Real Estate and Urban Land Economics</li><li> Religious Studies</li><li> Risk Management and Insurance</li><li> Sociology</li><li> Soil Science</li><li> Spanish (Spanish and Portuguese)</li></ul>|\n",
    "|0.503| 0.152| 0.237| 0.043| 0.045| 0.010| 0.009| <ul><li>Animal Health and Biomedical Sciences</li><li> Agronomy</li><li> Comparative Biosciences</li><li> East Asian Area Studies</li><li> German</li><li> Greek (Classics)</li><li> Latin (Classics)</li><li>Molecular and Environmental Toxicology Center</li><li> Pathology and Laboratory Medicine</li><li> Portuguese (Spanish and Portuguese)</li><li> Transportation and Public Utilities</li></ul>|\n",
    "|0.512| 0.378| 0.074|0.020| 0.009| 0.004| 0.004 |<ul><li>Asian American Studies</li><li> Biomedical Engineering</li><li> Comparative Literature</li><li> English</li><li> Emergency Medicine</li><li> French (French and Italian)</li><li> Gender and Women’s Studies</li><li> Human Oncology</li><li> Interdisciplinary Courses (Engineering)</li><li> Journalism and Mass Communication</li><li> La Follette School of Public Affairs</li><li> Latin American, Caribbean, and Iberian Studies</li><li> Management and Human Resources</li><li> Medical Physics</li><li> Scandinavian Studies</li></ul>|\n",
    "|0.693|0.220|  0.058| 0.013| 0.009| 0.003| 0.004|<ul><li> African Languages and Literature</li><li> American Indian Studies</li><li> Civil Society and Community Studies</li><li> Collaborative Nursing Program</li><li> Design Studies</li><li> East Asian Languages and Literature</li><li> Family and Consumer Communications</li><li> Folklore Program</li><li> Hebrew</li><li> Human Development and Family Studies</li><li> Industrial Relations</li><li> Information Systems</li><li> Integrated Arts</li><li> Life Sciences Communication</li><li> Physical Educ Activity Progm</li><li> Pharmacy</li><li> Radiology</li><li> Slavic (Slavic Languages)</li></ul>|\n",
    "|0.849|0.091| 0.039| 0.008| 0.007| 0.002| 0.004|<ul><li> Air Force Aerospace Studies</li><li> Consumer Science</li><li> Dance</li><li> Engineering Physics</li><li> General Business</li><li> Interdisciplinary Courses (CALS)</li><li> Interdisciplinary Courses (LandS)</li><li> Interdisciplinary Courses (SOHE)</li><li> Languages and Cultures of Asia - Languages</li><li> Professional Orientation</li></ul>|\n",
    "|.990| .004| .003| .001| .001| 0 |.001|<ul><li> Agroecology</li><li> Anatomy</li><li> Anesthesiology</li><li> Animal Sciences</li><li> Art Department</li><li> Art Education (Department of Art)</li><li> Biochemistry</li><li> Biomolecular Chemistry</li><li> Biostatistics and Medical Informatics</li><li> Cell and Regenerative Biology</li><li> Civil and Environmental Engineering</li><li> Communication Sciences and Disorders</li><li> Counseling Psychology</li><li> Curriculum and Instruction</li><li> Dairy Science</li><li> Educational Leadership and Policy Analysis</li><li> Educational Policy Studies</li><li> Educational Psychology</li><li> English</li><li> Entomology</li><li> Environmental Studies - Gaylord Nelson Institute</li><li> Family Medicine</li><li> Genetics</li><li> Hebrew-Modern</li><li> Industrial and Systems Engineering</li><li> Integrated Liberal Studies</li><li> Integrated Science</li><li> International Business</li><li> Kinesiology</li><li> Library and Information Studies</li><li> Materials Science and Engineering</li><li> Medical Genetics</li><li> Medical Microbiology and Immunology</li><li> Medical Sciences - Veterinary Medicine</li><li> Medicine</li><li> Microbiology</li><li> Military Science</li><li> Molecular Biology</li><li> Music</li><li> Music-Performance</li><li> Naval Science</li><li> Neurological Surgery</li><li> Neurology</li><li> Neuroscience</li><li> Neuroscience Training Program</li><li> Nursing</li><li> Obstetrics and Gynecology</li><li> Occupational Therapy (Department of Kinesiology)</li><li> Oncology</li><li> Ophthalmology and Visual Sciences</li><li> Patho-Biological Sciences</li><li> Pharmaceutical Sciences</li><li> Pharmacology</li><li> Pharmacy Practice</li><li> Physical Therapy</li><li> Physiology</li><li> Population Health Sciences</li><li> Psychology</li><li> Rehabilitation Psychology and Special Education</li><li> Science and Technology Studies</li><li> Social Work</li><li> Social and Administrative Pharmacy</li><li> Surgery</li><li> Surgical Sciences</li><li> Theatre and Drama</li><li> Therapeutic Science (Department of Kinesiology)</li><li> Urban and Regional Planning</li></ul>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
