{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor\n",
    "\n",
    "I produce a basic Decision Tree Regressor function and test it on subset of my cleaned UW_Madison GPA dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_perc</th>\n",
       "      <th>ab_perc</th>\n",
       "      <th>b_perc</th>\n",
       "      <th>bc_perc</th>\n",
       "      <th>c_perc</th>\n",
       "      <th>d_perc</th>\n",
       "      <th>f_perc</th>\n",
       "      <th>section_type</th>\n",
       "      <th>start_time</th>\n",
       "      <th>class_length</th>\n",
       "      <th>term_code</th>\n",
       "      <th>class_level</th>\n",
       "      <th>class_meetings</th>\n",
       "      <th>med_enrollment</th>\n",
       "      <th>number_sections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19124</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>LEC</td>\n",
       "      <td>870.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1122</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8538</td>\n",
       "      <td>0.432796</td>\n",
       "      <td>0.233871</td>\n",
       "      <td>0.231183</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>LEC</td>\n",
       "      <td>595.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1114</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61171</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>LEC</td>\n",
       "      <td>595.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1102</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16277</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>LEC</td>\n",
       "      <td>800.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1122</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21130</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>LEC</td>\n",
       "      <td>660.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1132</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a_perc   ab_perc    b_perc   bc_perc    c_perc    d_perc    f_perc  \\\n",
       "19124  0.500000  0.050000  0.300000  0.050000  0.050000  0.000000  0.050000   \n",
       "8538   0.432796  0.233871  0.231183  0.043011  0.021505  0.026882  0.005376   \n",
       "61171  0.089552  0.238806  0.402985  0.223881  0.014925  0.000000  0.029851   \n",
       "16277  0.227273  0.045455  0.136364  0.090909  0.272727  0.136364  0.090909   \n",
       "21130  0.148936  0.148936  0.276596  0.170213  0.180851  0.031915  0.021277   \n",
       "\n",
       "      section_type  start_time  class_length  term_code  class_level  \\\n",
       "19124          LEC       870.0          75.0       1122            3   \n",
       "8538           LEC       595.0          50.0       1114            2   \n",
       "61171          LEC       595.0          50.0       1102            2   \n",
       "16277          LEC       800.0          50.0       1122            3   \n",
       "21130          LEC       660.0          50.0       1132            3   \n",
       "\n",
       "       class_meetings  med_enrollment  number_sections  \n",
       "19124             2.0            18.0              6.0  \n",
       "8538              3.0           261.0              1.0  \n",
       "61171             3.0            62.0              2.0  \n",
       "16277             3.0            17.0              8.0  \n",
       "21130             3.0           127.0              1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('for_next_project.pkl').sample(500)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test splitting\n",
    "To begin with, I want to divide the data that I have into training and testing sets. Since the objective here is to build a decision tree that will continue to grow as long as it can continue to reduce variance (subject to possible restrictions on leaf splitting and maximum depth), I'm not going to worry about producing a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  390  elements in your training set. \n",
      " There are  110  elements in your test set\n"
     ]
    }
   ],
   "source": [
    "mask_list = np.random.random(len(df))\n",
    "\n",
    "train_mask = mask_list <= 0.80\n",
    "test_mask = mask_list > 0.80\n",
    "\n",
    "train_df = df[train_mask]\n",
    "test_df = df[test_mask]\n",
    "\n",
    "print('There are ', len(train_df), ' elements in your training set. \\n There are ', len(test_df), ' elements in your test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding\n",
    "\n",
    "Next, I need to one hot encode any categorical variables. We see that in this case, the only true categorical variable that I have is ```section_type```. Below, I've writting one function, ```oh_encoder_fit``` to find the encodings and another ```oh_encoder_transform``` to transform the dataframes. Since a few of the section types occur fairly infrequently, I'm going to cheat a bit and use ```oh_encoder_fit``` on my original dataframe and then transform my test and training dataframes separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh_encoder_fit(df, cat_vars):\n",
    "    \n",
    "#   df1 = df.copy()\n",
    "    cat_encodes = {}\n",
    "    \n",
    "    for cat_var in cat_vars:\n",
    "        cats = list(set(df[cat_var].values.tolist()))\n",
    "        cat_encodes[cat_var] = cats\n",
    "#        for cat in cats:\n",
    "#            df1[cat] = (df1[cat_var] == cat) * 1\n",
    "            \n",
    "#    df1.drop(cat_vars, axis = 1, inplace = True)\n",
    "                \n",
    "    return cat_encodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh_encoder_transform(df, cat_encodes):\n",
    "    \n",
    "    df1 = df.copy()\n",
    "    \n",
    "    for key in cat_encodes.keys():\n",
    "        cats = cat_encodes[key]\n",
    "        for cat in cats:\n",
    "            df1[cat] = (df1[key] == cat) * 1\n",
    "            \n",
    "        df1.drop(key, axis = 1, inplace = True)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Producing the categorical encodings for the entire data frame.\n",
    "\n",
    "cat_encodings = oh_encoder_fit(df, ['section_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = oh_encoder_transform(train_df, cat_encodings)\n",
    "test_df = oh_encoder_transform(test_df, cat_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_perc</th>\n",
       "      <th>ab_perc</th>\n",
       "      <th>b_perc</th>\n",
       "      <th>bc_perc</th>\n",
       "      <th>c_perc</th>\n",
       "      <th>d_perc</th>\n",
       "      <th>f_perc</th>\n",
       "      <th>start_time</th>\n",
       "      <th>class_length</th>\n",
       "      <th>term_code</th>\n",
       "      <th>class_level</th>\n",
       "      <th>class_meetings</th>\n",
       "      <th>med_enrollment</th>\n",
       "      <th>number_sections</th>\n",
       "      <th>FLD</th>\n",
       "      <th>LEC</th>\n",
       "      <th>DIS</th>\n",
       "      <th>LAB</th>\n",
       "      <th>SEM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19124</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>870.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1122</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16277</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>800.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1122</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21130</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>660.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1132</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4427</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>530.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1072</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12223</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>570.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1134</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a_perc   ab_perc    b_perc   bc_perc    c_perc    d_perc    f_perc  \\\n",
       "19124  0.500000  0.050000  0.300000  0.050000  0.050000  0.000000  0.050000   \n",
       "16277  0.227273  0.045455  0.136364  0.090909  0.272727  0.136364  0.090909   \n",
       "21130  0.148936  0.148936  0.276596  0.170213  0.180851  0.031915  0.021277   \n",
       "4427   0.562500  0.125000  0.125000  0.000000  0.125000  0.062500  0.000000   \n",
       "12223  0.210526  0.210526  0.578947  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       start_time  class_length  term_code  class_level  class_meetings  \\\n",
       "19124       870.0          75.0       1122            3             2.0   \n",
       "16277       800.0          50.0       1122            3             3.0   \n",
       "21130       660.0          50.0       1132            3             3.0   \n",
       "4427        530.0          50.0       1072            1             4.0   \n",
       "12223       570.0          75.0       1134            2             2.0   \n",
       "\n",
       "       med_enrollment  number_sections  FLD  LEC  DIS  LAB  SEM  \n",
       "19124            18.0              6.0    0    1    0    0    0  \n",
       "16277            17.0              8.0    0    1    0    0    0  \n",
       "21130           127.0              1.0    0    1    0    0    0  \n",
       "4427             15.0              2.0    0    1    0    0    0  \n",
       "12223            19.0             21.0    0    1    0    0    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the features used to predict\n",
    "\n",
    "Looking at the training dataframe above, we see that we actually have 7 response columns and 12 feature columns. To begin with, let's eliminate all but the first response column because I haven't writting a decision tree that can handle multiple features at the same time. Secondly, I want to eliminate ```term_code```, ```start_time```, ```class_level```, and ```class_meetings``` from the feature columns because past experimentation has demonstrated that it actually isn't all that helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['ab_perc', 'b_perc', 'bc_perc', 'c_perc', 'd_perc', 'f_perc', 'term_code', 'start_time', 'class_level', 'class_meetings'], axis = 1, inplace = True)\n",
    "test_df.drop(['ab_perc', 'b_perc', 'bc_perc', 'c_perc', 'd_perc', 'f_perc', 'term_code', 'start_time', 'class_level',  'class_meetings'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_perc</th>\n",
       "      <th>class_length</th>\n",
       "      <th>med_enrollment</th>\n",
       "      <th>number_sections</th>\n",
       "      <th>FLD</th>\n",
       "      <th>LEC</th>\n",
       "      <th>DIS</th>\n",
       "      <th>LAB</th>\n",
       "      <th>SEM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19124</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16277</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>50.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21130</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>50.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4427</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12223</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>75.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         a_perc  class_length  med_enrollment  number_sections  FLD  LEC  DIS  \\\n",
       "19124  0.500000          75.0            18.0              6.0    0    1    0   \n",
       "16277  0.227273          50.0            17.0              8.0    0    1    0   \n",
       "21130  0.148936          50.0           127.0              1.0    0    1    0   \n",
       "4427   0.562500          50.0            15.0              2.0    0    1    0   \n",
       "12223  0.210526          75.0            19.0             21.0    0    1    0   \n",
       "\n",
       "       LAB  SEM  \n",
       "19124    0    0  \n",
       "16277    0    0  \n",
       "21130    0    0  \n",
       "4427     0    0  \n",
       "12223    0    0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_df)\n",
    "test_data = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_response = train_data[:, 0]\n",
    "train_features = train_data[:, 1:]\n",
    "\n",
    "test_response = test_data[:, 0]\n",
    "test_features = train_data[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the impurity reduction for a regression tree.\n",
    "\n",
    "$$I_{V}(N)={\\frac {1}{|S|^{2}}}\\sum _{i\\in S}\\sum _{j\\in S}{\\frac {1}{2}}(x_{i}-x_{j})^{2}-\\left({\\frac {1}{|S_{t}|^{2}}}\\sum _{i\\in S_{t}}\\sum _{j\\in S_{t}}{\\frac {1}{2}}(x_{i}-x_{j})^{2}+{\\frac {1}{|S_{f}|^{2}}}\\sum _{i\\in S_{f}}\\sum _{j\\in S_{f}}{\\frac {1}{2}}(x_{i}-x_{j})^{2}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_reduction(response1, response2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the impurity reduction for a given split in a decision tree.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    response1 : list \n",
    "        Contains the response values for the first part of the split\n",
    "    response2 : list\n",
    "        Contains the response values for the second part of the split\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The reduction (if positive) or increase (if negative) in the impurity with the specified split\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    data_array = np.concatenate((response1, response2), axis = 0)\n",
    "    \n",
    "    sum_da = 0\n",
    "    for i in range(len(data_array)):\n",
    "        for j in range(len(data_array)):\n",
    "            sum_da += 0.5 * (data_array[i] - data_array[j])**2\n",
    "    #print(sum_da, len(data_array))        \n",
    "    sum_da = sum_da / (len(data_array))**2\n",
    "   # print(\"The sum for the whole array is\", sum_da)\n",
    "    sum_da1 = 0\n",
    "    for i in range(len(response1)):\n",
    "        for j in range(len(response1)):\n",
    "            sum_da1 += 0.5 * (response1[i] - response1[j])**2\n",
    "    #print(sum_da1, len(response1)    )    \n",
    "    sum_da1 = sum_da1 / (len(response1))**2\n",
    "    #print(\"The sum for response 1 is\", sum_da1)\n",
    "    sum_da2 = 0\n",
    "    for i in range(len(response2)):\n",
    "        for j in range(len(response2)):\n",
    "            sum_da2 += 0.5 * (response2[i] - response2[j])**2\n",
    "    #print(sum_da2, len(response2)     )   \n",
    "\n",
    "    sum_da2 = sum_da2 / (len(response2))**2\n",
    "    #print(\"The sum for response 2 is\", sum_da2)\n",
    "\n",
    "\n",
    "    reduction = sum_da - (sum_da1 + sum_da2)\n",
    "    \n",
    "    return reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split_one(da, col, response):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds the best split for a single column (feature) in a data array\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : numpy array \n",
    "        Contains the feature values\n",
    "    col : int\n",
    "        The column of interest\n",
    "    response : list\n",
    "        Contains the response values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float or None\n",
    "        The best value at which to split for the specified column, \n",
    "        None if none of the possible splits produce a reduction in impurity\n",
    "    float\n",
    "        The reduction in impurity with the best split for the specified column\n",
    "        0 if none of the possible splits produce a reduction in impurity\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Here we are looking for the best split for a single variable for a regression problem\n",
    "    \n",
    "    \n",
    "    current_red = 0\n",
    "    \n",
    "    to_split = None\n",
    "    values = sorted(list(set(da[:, col])))\n",
    "    #print(\"the values found for column {} are\".format(col), values)\n",
    "\n",
    "    for i in range(len(values) - 1):\n",
    "        keys_a = [val for val in (da[:, col] <= values[i])]\n",
    "        resp_a = response[keys_a]\n",
    "        #print(len(resp_a))\n",
    "        keys_b = [val for val in (da[:, col] > values[i])]\n",
    "        resp_b = response[keys_b]\n",
    "       # print(len(resp_b))\n",
    "        new_red = variance_reduction(resp_a, resp_b)\n",
    "        \n",
    "        if new_red > current_red:\n",
    "            current_red = new_red\n",
    "            to_split = values[i]\n",
    "\n",
    "    return to_split, current_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(da, response):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds the best split across all possible variables in a data array\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : numpy array \n",
    "        Contains the feature values\n",
    "    response : list\n",
    "        Contains the response values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The best column on which to split\n",
    "    float or None\n",
    "        The best value at which to split for the best column, \n",
    "        None if there are no possible splits which produce a reduction in impurity\n",
    "    float\n",
    "        The reduction in impurity with the best split for the specified column\n",
    "        0 if there are no possible splits which produce a reduction in impurity\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_cols = da.shape[1]\n",
    "    best_current_red = 0\n",
    "    best_split = None\n",
    "    var_to_split = None\n",
    "    var_type = None\n",
    "    for col in range(num_cols):\n",
    "        try:\n",
    "            to_split, new_red = find_best_split_one(da, col, response)\n",
    "        except:\n",
    "            to_split = None\n",
    "            new_red = 0\n",
    "        if new_red > best_current_red:\n",
    "            best_current_red = new_red\n",
    "            var_to_split = col\n",
    "            best_split = to_split\n",
    "    \n",
    "    return var_to_split, best_split, best_current_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_masks(mask1, mask2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Combines two boolean masks in an 'AND' fashion, so that the resulting mask\n",
    "    is True exactly where the two input masks were true\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask1 : list \n",
    "        Contains boolean values\n",
    "    mask2 : list\n",
    "        Contains boolean values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A boolean combination of the input masks\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    new_mask = mask1*mask2\n",
    "    new_mask = [True if value == 1 else False for value in new_mask]\n",
    "    \n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(da, split_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds a subarray of a data array which satisfies the conditions of the specified list\n",
    "    of data splits\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : numpy array \n",
    "        Contains the feature values\n",
    "    split_list : list\n",
    "        A list of splits to follow to create a leaf of a decision tree. Each split is a list\n",
    "        of the form [column, value, side] where:\n",
    "        \n",
    "        column: int\n",
    "            the column we are splitting based on\n",
    "        value: float\n",
    "            the decision value for the column\n",
    "        side : 0 or 1\n",
    "            if side = 0, we keep values <= value\n",
    "            if side = 1, we keep values > value\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "        Contains the rows of the input data array which satisfied each split in order\n",
    "    list\n",
    "        A boolean list indicating which rows of the data array were retained\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # The split list is a list of the splits to follow to create a leaf of the current decision tree\n",
    "    # It contains lists and each of the interior lists is of the form [column, value, side (0, 1)]\n",
    "    \n",
    "    da_split = da.copy()\n",
    "    mask = [True for i in range(da.shape[0])]  \n",
    "    \n",
    "    for i in range(len(split_list)):\n",
    "        col, val, side = split_list[i]\n",
    "        if side == 0:\n",
    "            da_split = da_split[da_split[:, col] <= val]\n",
    "            keepers = da[:, col] <= val\n",
    "            mask = combine_masks(mask, keepers)\n",
    "        else:\n",
    "            da_split = da_split[da_split[:, col] > val]\n",
    "            keepers = da[:, col] > val\n",
    "            mask = combine_masks(mask, keepers)\n",
    "                \n",
    "    return da_split, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(da, response, min_splitting = 2, max_depth = 10):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the leaves of a decision tree\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : numpy array \n",
    "        Contains the feature values\n",
    "    response: list\n",
    "        Contains the response values\n",
    "    min_splitting : int\n",
    "        The minimum number of elements required to split a leaf, default value is 2\n",
    "    max_depth : int\n",
    "        The maximum depth of a leaf, default value is 10\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of lists of splits to follow for each leaf. \n",
    "        Each split is of the form [column, value, side] where:\n",
    "        \n",
    "        column: int\n",
    "            the column we are splitting based on\n",
    "        value: float\n",
    "            the decision value for the column\n",
    "        side : 0 or 1\n",
    "            if side = 0, we keep values <= value\n",
    "            if side = 1, we keep values > value\n",
    "    \"\"\"\n",
    "\n",
    "    splits_so_far = []\n",
    "    \n",
    "    keep_going = True\n",
    "    \n",
    "    # Finding the first split\n",
    "    \n",
    "    var_to_split, best_split, best_current_red = find_best_split(da, response)\n",
    "    \n",
    "    if best_current_red > 0:\n",
    "        splits_so_far = [[[var_to_split, best_split, 0]], \n",
    "                     [[var_to_split,best_split, 1]]]\n",
    "    else:\n",
    "        keep_going = False\n",
    "\n",
    "    while keep_going:\n",
    "        # I'm going to need to consider some number of possible leaves here, where at\n",
    "        # most these are going to be equal to the product of the number of possible values\n",
    "\n",
    "        current_index = -1\n",
    "        current_split = None\n",
    "        current_cat = None\n",
    "        current_var = None\n",
    "        current_decr = 0\n",
    "        \n",
    "        # Finding (hopefully) the best split among the possibilities\n",
    "        for i in range(len(splits_so_far)):\n",
    "            \n",
    "            if len(splits_so_far[i]) < max_depth:\n",
    "                split_da, mask = split_data(da, splits_so_far[i])\n",
    "\n",
    "                if len(split_da) >= min_splitting:\n",
    "                    var_to_split, best_split, best_current_red = find_best_split(split_da, response[mask])\n",
    "                    if best_current_red > current_decr:\n",
    "                        current_index = i\n",
    "                        current_split = best_split\n",
    "                        current_var = var_to_split\n",
    "        \n",
    "        # And adding its data to my branching tree...\n",
    "        \n",
    "        if current_split != None:\n",
    "            splits_so_far.insert(current_index, splits_so_far[current_index].copy())\n",
    "            splits_so_far[current_index].append([current_var, current_split, 0])\n",
    "            splits_so_far[current_index + 1].append([current_var, current_split, 1])\n",
    "                    \n",
    "        else:\n",
    "            keep_going = False\n",
    "        \n",
    "    return splits_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_mean(da, split, response):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes the mean of the responses for a specified leaf\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : list \n",
    "        Contains the feature values\n",
    "        \n",
    "    split : list\n",
    "        A list of lists of splits to follow for each leaf. \n",
    "        Each split is of the form [column, value, side] where:\n",
    "        \n",
    "        column: int\n",
    "            the column we are splitting based on\n",
    "        value: float\n",
    "            the decision value for the column\n",
    "        side : 0 or 1\n",
    "            if side = 0, we keep values <= value\n",
    "            if side = 1, we keep values > value\n",
    "            \n",
    "    response : list\n",
    "        Contains the response values\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dictionary\n",
    "        The means of the responses for the data retained in each leaf\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    means = {}\n",
    "    \n",
    "    for i in range(len(split)):\n",
    "        leaf_da, mask = split_data(da, split[i])\n",
    "        mean = np.mean(response[mask])\n",
    "        means[i] = mean\n",
    "        \n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_split(point, split):\n",
    "\n",
    "    \"\"\"\n",
    "    Determines whether or not a given point belongs to a given leaf\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    point : list \n",
    "        Contains the feature values for a single observation\n",
    "        \n",
    "    split : list\n",
    "        Contains the splits to perform. Each split is of the form [column, value, side] where:\n",
    "        \n",
    "        column: int\n",
    "            the column we are splitting based on\n",
    "        value: float\n",
    "            the decision value for the column\n",
    "        side : 0 or 1\n",
    "            if side = 0, we keep values <= value\n",
    "            if side = 1, we keep values > value\n",
    "                    \n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "        True if the observation belongs to the specified leaf, \n",
    "        False otherwise\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    col, val, side = split\n",
    "    if side == 0:\n",
    "        if point[col] <= val:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if point[col] > val:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_value(test_da, row, leaf_splits, means):\n",
    "\n",
    "    \"\"\"\n",
    "    Predicts the value for a observation, that is to say for a single row of a test array\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_da : numpy array \n",
    "        Contains the feature values the test data\n",
    "        \n",
    "    row : int\n",
    "        The row number of the observation for which we are predicting an outcome\n",
    "        \n",
    "    leaf_splits : list\n",
    "        A list of lists of splits to follow for each leaf. \n",
    "        Each split is of the form [column, value, side] where:\n",
    "        \n",
    "        column: int\n",
    "            the column we are splitting based on\n",
    "        value: float\n",
    "            the decision value for the column\n",
    "        side : 0 or 1\n",
    "            if side = 0, we keep values <= value\n",
    "            if side = 1, we keep values > value\n",
    "            \n",
    "    means : dictionary\n",
    "        The means of the responses for the data retained in each leaf\n",
    "                    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The predicted response for the given observation\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    leaf = None\n",
    "        \n",
    "    test_point = test_da[row, :]\n",
    "    \n",
    "    for j in range(len(leaf_splits)):\n",
    "\n",
    "        current_leaf = leaf_splits[j]\n",
    "    \n",
    "        tests = []\n",
    "        for i in range(len(current_leaf)):\n",
    "            tests.append(verify_split(test_point, current_leaf[i]))\n",
    "    \n",
    "        if False not in tests:\n",
    "            leaf = j\n",
    "            break\n",
    "        \n",
    "    return means[leaf]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(test_da, leaf_splits, means):\n",
    "\n",
    "    \"\"\"\n",
    "    Predicts the value for all observations in an array\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_da : numpy array \n",
    "        Contains the feature values the test data\n",
    "                \n",
    "    leaf_splits : list\n",
    "        A list of lists of splits to follow for each leaf. \n",
    "        Each split is of the form [column, value, side] where:\n",
    "        \n",
    "        column: int\n",
    "            the column we are splitting based on\n",
    "        value: float\n",
    "            the decision value for the column\n",
    "        side : 0 or 1\n",
    "            if side = 0, we keep values <= value\n",
    "            if side = 1, we keep values > value\n",
    "            \n",
    "    means : dictionary\n",
    "        The means of the responses for the data retained in each leaf\n",
    "                    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The predicted responses for the given observations\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(test_da.shape[0]):\n",
    "        prediction = predict_one_value(test_da, i, leaf_splits, means)\n",
    "        predicted.append([prediction])\n",
    "            \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_true, y_pred):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the mean squared error of predicted responses\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : list \n",
    "        The observed values of the response variable\n",
    "        \n",
    "    y_pred : list\n",
    "        The predicted values of the response variable\n",
    "                            \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The mean squared error of the predicted values\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    squared_diff = [(y_true[i] - y_pred[i])**2 for i in range(len(y_true))]\n",
    "    sum_of_squares = sum(squared_diff)\n",
    "    \n",
    "    mse = sum_of_squares/len(y_true)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y_true, y_pred):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the mean absolute error of predicted responses\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : list \n",
    "        The observed values of the response variable\n",
    "        \n",
    "    y_pred : list\n",
    "        The predicted values of the response variable\n",
    "                            \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The mean absolute error of the predicted values\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    abs_diff = [abs(y_true[i] - y_pred)[i] for i in range(len(y_true))]\n",
    "    sum_of_abs_diff = sum(abs_diff)\n",
    "    \n",
    "    mae = sum_of_abs_diff/len(y_true)\n",
    "    \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = decision_tree(train_features, train_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = leaf_mean(train_features, splits, train_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_response = predictions(test_features, splits, means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error in this prediction is: [0.075]\n",
      "The mean absolute error in this prediction is: [0.234]\n"
     ]
    }
   ],
   "source": [
    "mean_squared_error = MSE(test_response, pred_response)\n",
    "mean_absolute_error = MAE(test_response, pred_response)\n",
    "\n",
    "print('The mean squared error in this prediction is: {}'.format(np.around(mean_squared_error, 3)))\n",
    "print('The mean absolute error in this prediction is: {}'.format(np.around(mean_absolute_error, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
